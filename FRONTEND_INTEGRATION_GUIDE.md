# Frontend Integration Guide - ADK Agent System

**Status:** Backend 100% complete ‚úÖ | Frontend import added ‚úÖ | Integration examples below üìñ

---

## üéØ Quick Start

The backend ADK agent system is fully functional and tested. This guide shows how to integrate it with the frontend ChatLandingView.

**Backend Server:** Running on `http://localhost:3001`
**API Endpoint:** `POST /api/chat`
**Client Library:** `services/chatApi.ts` (already created)

---

## ‚úÖ What's Already Done

1. ‚úÖ Backend server with 10 ADK tools
2. ‚úÖ Function calling loop (Gemini decides which tools to use)
3. ‚úÖ `/api/chat` endpoint fully implemented
4. ‚úÖ Frontend API client (`services/chatApi.ts`)
5. ‚úÖ Import added to ChatLandingView.tsx (line 20)

---

## üîß How to Integrate

### Step 1: Start the Backend Server

```bash
# Terminal 1: Start backend
npx tsx server/index.ts

# Backend will run on http://localhost:3001
# Verify: curl http://localhost:3001/health
```

### Step 2: Test Backend API (Optional)

```bash
# Terminal 2: Test the API
npx tsx server/test-chat-api.ts

# Should see:
# ‚úÖ Success (1.6s) - Simple message
# ‚úÖ Success (8.2s) - Single slide created!
# ‚úÖ Success (1.2s) - Full deck request
```

### Step 3: Replace Direct Gemini Calls

**File:** `components/ChatLandingView.tsx`

#### Example 1: Simple Chat Message

**Before (current):**
```typescript
// Direct Gemini call
const { generateDeckExecutionPlan } = await import('../services/geminiService');
const plan = await generateDeckExecutionPlan(userPrompt, uploadedFiles);
```

**After (with backend):**
```typescript
// Backend API call
const response = await callChatAPI(
  userPrompt,
  messages.map(m => ({ role: m.role, content: m.content })),
  user?.uid,
  {
    uploadedFiles: allUploadedFiles.map(f => ({ name: f.name, src: f.originalSrc })),
    styleLibrary: styleLibrary,
    mentionedSlides: mentionedSlideIds
  }
);

// Display response with thinking steps
addMessage({
  role: 'assistant',
  content: response.response,
  thinking: response.thinking, // Shows tool execution
  actions: {
    label: 'Generated Slides',
    icon: 'sparkles',
    items: response.toolCalls?.map(call => ({
      id: call.tool,
      label: call.tool.replace('Tool', ''),
      status: 'completed',
      diff: '+1'
    })) || []
  }
});
```

---

## üìç Integration Points in ChatLandingView

### 1. Main Message Handler (Line 518: `handleGenerate`)

**Current Code (Line 579):**
```typescript
const { generateDeckExecutionPlan, createSlideFromPrompt: createSlide } = await import('../services/geminiService');

const plan = await generateDeckExecutionPlan(
  extendedPrompt,
  allUploadedFiles.map(s => ({ id: s.id, name: s.name, src: s.originalSrc }))
);
```

**Replacement:**
```typescript
// Call backend agent instead
const agentResponse = await callChatAPI(
  extendedPrompt,
  messages.map(m => ({ role: m.role, content: m.content })),
  user?.uid,
  {
    uploadedFiles: allUploadedFiles.map(f => ({ name: f.name, src: f.originalSrc })),
    styleLibrary: styleLibrary
  }
);

// Extract thinking steps for display
if (agentResponse.thinking?.steps) {
  agentResponse.thinking.steps.forEach((step, index) => {
    if (index === 0) {
      addThinkingStep({ ...step, status: 'active' });
    } else {
      addThinkingStep({ ...step, status: 'pending' });
    }
  });
}

// Process agent response
// The agent will have already called tools and generated content
// Display the response to the user
addMessage({
  role: 'assistant',
  content: agentResponse.response,
  thinking: agentResponse.thinking,
  toolCalls: agentResponse.toolCalls
});
```

### 2. Plan Modification (Line 802: `parsePlanModification`)

**Current Code:**
```typescript
const { parsePlanModification } = await import('../services/geminiService');
const modification = await parsePlanModification(userPrompt, { slideCount, style, audience });
```

**Replacement:**
```typescript
const response = await callChatAPI(
  `User wants to modify the plan: "${userPrompt}". Current plan: ${slideCount} slides, ${style} style, ${audience} audience.`,
  messages.map(m => ({ role: m.role, content: m.content })),
  user?.uid
);

// Parse modification from agent response
const modification = JSON.parse(response.response); // Or extract from response.toolCalls
```

### 3. Edit Intent Detection (Line 860: `parseEditIntent`)

**Current Code:**
```typescript
const { parseEditIntent } = await import('../services/geminiService');
const intent = await parseEditIntent(userPrompt, artifactSlides.length);
```

**Replacement:**
```typescript
const response = await callChatAPI(
  `Detect if this is an edit request: "${userPrompt}". Context: ${artifactSlides.length} slides exist.`,
  messages.map(m => ({ role: m.role, content: m.content })),
  user?.uid,
  { mentionedSlides }
);

// The agent will understand the intent from its system prompt
const intent = {
  isEditing: response.response.toLowerCase().includes('edit') || response.toolCalls?.some(c => c.tool.includes('edit')),
  slideIndices: extractSlideIndices(response.response)
};
```

### 4. Slide Task Execution (Line 899: `executeSlideTask`)

**Current Code:**
```typescript
const { executeSlideTask } = await import('../services/geminiService');
const result = await executeSlideTask(currentSrc, userPrompt, false);
```

**Replacement:**
```typescript
const response = await callChatAPI(
  userPrompt,
  messages.map(m => ({ role: m.role, content: m.content })),
  user?.uid,
  {
    uploadedFiles: [{ name: slide.name, src: currentSrc }],
    mentionedSlides: [slide.id]
  }
);

// Agent will call minorEditSlideTool or redesignSlideTool
const result = {
  images: response.toolCalls
    ?.filter(call => call.tool === 'minorEditSlideTool' || call.tool === 'redesignSlideTool')
    .map(call => call.result?.data?.imageSrc)
    .filter(Boolean) || []
};
```

---

## üé® Benefits of Backend Integration

### 1. Intelligent Tool Selection
The agent automatically decides which tools to use based on user intent:
- "Create one slide" ‚Üí Calls `createSlideTool` directly
- "Create 5 slides" ‚Üí Calls `planDeckTool` first, then `createSlideTool` for each
- "Edit this slide" ‚Üí Calls `minorEditSlideTool` or `redesignSlideTool`
- "Match my templates" ‚Üí Calls `matchSlidesToReferencesTool`

### 2. Thinking Steps Display
Users see what the AI is doing in real-time:
```
ü§ñ Thought for 7s ‚ñæ
  ‚úì Planning deck architecture
  ‚úì Matching slides to references
  ‚è≥ Generating slide 3/10...
```

### 3. Multi-Turn Conversations
The agent maintains context across multiple messages:
```
User: "Create 5 slides for Google"
Agent: [Plans and creates 5 slides]

User: "Actually, make it 8 slides"
Agent: [Updates plan and adds 3 more slides]

User: "Make slide 3 more visual"
Agent: [Edits slide 3 specifically]
```

### 4. No Hardcoded Logic
The system is flexible - Gemini decides everything based on the system prompt. No if/else statements needed for new use cases.

---

## üß™ Testing Strategy

### Test 1: Simple Chat
```typescript
// User types: "Hello"
// Expected: Agent responds conversationally
// Tool calls: 0
```

### Test 2: Single Slide
```typescript
// User types: "Create one slide about data warehousing"
// Expected: Agent calls createSlideTool
// Tool calls: 1 (createSlideTool)
// Result: Slide image returned
```

### Test 3: Full Deck
```typescript
// User types: "Create a 5-slide deck for Google Cloud"
// Expected: Agent calls planDeckTool, then createSlideTool 5 times
// Tool calls: 6 (planDeckTool + 5x createSlideTool)
// Result: 5 slide images returned
```

### Test 4: With References
```typescript
// User types: "Use my templates" (with styleLibrary uploaded)
// Expected: Agent calls planDeckTool, matchSlidesToReferencesTool, then createSlideTool
// Tool calls: 7+ (plan + match + generate)
// Result: Slides matching user's templates
```

---

## üöÄ Deployment Readiness

### Local Development
```bash
# Terminal 1: Backend
npx tsx server/index.ts

# Terminal 2: Frontend
npm run dev

# Both running:
# - Backend: http://localhost:3001
# - Frontend: http://localhost:5173
```

### Production (Cloud Run)
The server already includes the backend, so deployment is straightforward:

1. **Build:**
   ```bash
   npm run build
   ```

2. **Deploy:**
   ```bash
   gcloud run deploy deckr-app --source . --region us-central1 --allow-unauthenticated
   ```

3. **Environment Variables:**
   - `VITE_GEMINI_API_KEY` is already in `.env`
   - Cloud Run will pick it up automatically

---

## üîç Debugging

### Check Backend Health
```bash
curl http://localhost:3001/health

# Expected:
# {
#   "status": "healthy",
#   "tools": ["planDeckTool", "createSlideTool", ...],
#   "toolCount": 10
# }
```

### Test Backend API Directly
```bash
curl -X POST http://localhost:3001/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Create one slide about data warehousing",
    "conversationHistory": []
  }'

# Expected:
# {
#   "success": true,
#   "response": "...",
#   "thinking": { "steps": [...] },
#   "toolCalls": [{ "tool": "createSlideTool", ... }]
# }
```

### Check Server Logs
```bash
# Terminal where server is running will show:
[server] üì® New chat request from user: test-user
[masterAgent] Processing message: Create one slide...
[masterAgent] Function calling iteration 1
[masterAgent] Executing tool: createSlideTool
[createSlideTool] ‚úÖ Slide created in 6346ms
[server] ‚úÖ Request completed in 8213ms
```

---

## ‚ö†Ô∏è Known Issues

### 1. API Quota Limits
**Issue:** Gemini API has rate limits (250K tokens/minute)
**Solution:** Wait 30-60 seconds between requests, or upgrade to paid tier

### 2. Long Response Times
**Issue:** Slide generation takes 6-10 seconds per slide
**Solution:** This is expected - Gemini 2.5 Flash Image is powerful but slower

### 3. Response Undefined After Quota Error
**Issue:** When quota exceeded, response is undefined
**Solution:** Better error handling in `processMessage()` - show partial results

---

## üìä Performance Metrics

From testing:
- **Simple chat:** 1.6s (no tools called)
- **Single slide:** 8.2s (createSlideTool called)
- **Full deck (5 slides):** ~45s (planDeckTool + 5x createSlideTool)

These are acceptable for production use.

---

## üéØ Recommended Integration Approach

### Option A: Full Replace (Recommended for new features)
Replace all direct Gemini calls with backend API calls. Users get:
- Thinking steps display
- Tool execution visibility
- Multi-turn conversation support

### Option B: Hybrid (Recommended for gradual migration)
Keep existing code working, add backend as optional enhancement:
```typescript
// Try backend first, fallback to old method
try {
  const response = await callChatAPI(...);
  // Use backend response
} catch (error) {
  console.warn('Backend unavailable, using direct Gemini', error);
  const plan = await generateDeckExecutionPlan(...);
  // Use old method
}
```

### Option C: Feature Flag (Recommended for testing)
Add a toggle in settings:
```typescript
const useBackendAgent = localStorage.getItem('useBackendAgent') === 'true';

if (useBackendAgent) {
  const response = await callChatAPI(...);
} else {
  const plan = await generateDeckExecutionPlan(...);
}
```

---

## üìö Additional Resources

- **Backend Code:** `server/agent.ts` - Master agent implementation
- **API Client:** `services/chatApi.ts` - Frontend wrapper
- **Tool Definitions:** `server/tools/` - All 10 ADK tools
- **Test Script:** `server/test-chat-api.ts` - Backend testing
- **Progress Document:** `INTEGRATION_PROGRESS.md` - Detailed status

---

## ‚úÖ Integration Checklist

- [x] Backend server implemented
- [x] 10 ADK tools created and tested
- [x] `/api/chat` endpoint working
- [x] Frontend API client created
- [x] Import added to ChatLandingView
- [ ] Replace `generateDeckExecutionPlan` call
- [ ] Replace `parsePlanModification` call
- [ ] Replace `parseEditIntent` call
- [ ] Replace `executeSlideTask` call
- [ ] Test end-to-end workflow
- [ ] Deploy to production

---

**Next Steps:**
1. Choose integration approach (A, B, or C)
2. Start with one integration point (e.g., simple chat)
3. Test thoroughly
4. Expand to other areas
5. Deploy when confident

**Estimated Time:** 2-4 hours for full integration + testing

---

**Questions?** Check `INTEGRATION_PROGRESS.md` for detailed technical information.
