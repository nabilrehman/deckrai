{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vector Search 2.0 Experiment: Slide Library\n",
        "\n",
        "This notebook tests Vector Search 2.0 for managing presentation slide libraries.\n",
        "\n",
        "**Run this in Google Colab for easiest setup!**\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install google-cloud-aiplatform pdf2image Pillow --quiet\n",
        "\n",
        "# Authenticate (in Colab, this will prompt for login)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set your project ID\n",
        "PROJECT_ID = 'deckr-477706'\n",
        "LOCATION = 'us-central1'\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Generate Embeddings for Slides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vertexai.vision_models import Image, MultiModalEmbeddingModel\n",
        "import vertexai\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Load embedding model\n",
        "model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding@001\")\n",
        "\n",
        "def generate_slide_embedding(image_path: str, description: str = \"presentation slide\"):\n",
        "    \"\"\"Generate embedding for a slide image\"\"\"\n",
        "    image = Image.load_from_file(image_path)\n",
        "    embeddings = model.get_embeddings(\n",
        "        image=image,\n",
        "        contextual_text=description,\n",
        "        dimension=512  # Use 512 for faster processing\n",
        "    )\n",
        "    return embeddings.image_embedding\n",
        "\n",
        "print(\"‚úÖ Embedding function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Upload Your PDF\n",
        "\n",
        "Upload your `title_slide.pdf` using the file upload button in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from pdf2image import convert_from_path\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Upload PDF\n",
        "print(\"üì§ Upload your PDF file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the PDF filename\n",
        "pdf_filename = list(uploaded.keys())[0]\n",
        "print(f\"\\n‚úÖ Uploaded: {pdf_filename}\")\n",
        "\n",
        "# Convert PDF to images\n",
        "print(\"\\nüîÑ Converting PDF to images...\")\n",
        "images = convert_from_path(pdf_filename)\n",
        "\n",
        "# Save images temporarily\n",
        "temp_dir = tempfile.mkdtemp()\n",
        "image_paths = []\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "    image_path = os.path.join(temp_dir, f\"slide_{i+1}.png\")\n",
        "    image.save(image_path, 'PNG')\n",
        "    image_paths.append(image_path)\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(images)} slides\")\n",
        "\n",
        "# Display first slide\n",
        "print(\"\\nüì∏ Preview of Slide 1:\")\n",
        "images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Embeddings for All Slides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Generate embeddings for each slide\n",
        "slide_data = []\n",
        "\n",
        "print(\"üìä Generating embeddings for all slides...\\n\")\n",
        "\n",
        "for i, image_path in enumerate(image_paths):\n",
        "    print(f\"Processing slide {i+1}/{len(image_paths)}...\", end=\" \")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Generate embedding\n",
        "    embedding = generate_slide_embedding(image_path, \"presentation slide\")\n",
        "    \n",
        "    # Store data\n",
        "    slide_data.append({\n",
        "        'id': f'slide-{i+1}',\n",
        "        'name': f'Slide {i+1}',\n",
        "        'slide_number': i+1,\n",
        "        'image_path': image_path,\n",
        "        'embedding': embedding,\n",
        "        'deck_name': pdf_filename\n",
        "    })\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"‚úÖ ({elapsed:.2f}s)\")\n",
        "\n",
        "print(f\"\\n‚úÖ Generated embeddings for {len(slide_data)} slides\")\n",
        "print(f\"üìè Embedding dimension: {len(slide_data[0]['embedding'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Query for \"Title Slide\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def query_slides(query_text: str, top_k: int = 5):\n",
        "    \"\"\"Query slides by text\"\"\"\n",
        "    print(f\"üîç Query: \\\"{query_text}\\\"\\n\")\n",
        "    \n",
        "    # Generate embedding for query text\n",
        "    query_embeddings = model.get_embeddings(\n",
        "        contextual_text=query_text,\n",
        "        dimension=512\n",
        "    )\n",
        "    query_embedding = query_embeddings.text_embedding\n",
        "    \n",
        "    # Calculate similarity with all slides\n",
        "    results = []\n",
        "    for slide in slide_data:\n",
        "        similarity = cosine_similarity(query_embedding, slide['embedding'])\n",
        "        results.append({\n",
        "            **slide,\n",
        "            'similarity': similarity\n",
        "        })\n",
        "    \n",
        "    # Sort by similarity\n",
        "    results.sort(key=lambda x: x['similarity'], reverse=True)\n",
        "    \n",
        "    # Return top K\n",
        "    return results[:top_k]\n",
        "\n",
        "# Test query\n",
        "results = query_slides(\"title slide cover page presentation\")\n",
        "\n",
        "# Display results\n",
        "print(\"üìä Top Results:\\n\")\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"[{i+1}] Slide {result['slide_number']}\")\n",
        "    print(f\"    Similarity: {result['similarity']:.4f}\")\n",
        "    print(f\"    Name: {result['name']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Visualize Top Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show top 3 results\n",
        "fig, axes = plt.subplots(1, min(3, len(results)), figsize=(15, 5))\n",
        "if len(results) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, result in enumerate(results[:3]):\n",
        "    img = PILImage.open(result['image_path'])\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"Slide {result['slide_number']}\\nSimilarity: {result['similarity']:.4f}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Test Different Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different query types\n",
        "test_queries = [\n",
        "    \"title slide\",\n",
        "    \"content slide with bullet points\",\n",
        "    \"data visualization chart graph\",\n",
        "    \"section divider\",\n",
        "    \"closing slide thank you\"\n",
        "]\n",
        "\n",
        "print(\"üß™ Testing Multiple Queries\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for query in test_queries:\n",
        "    results = query_slides(query, top_k=3)\n",
        "    print(f\"\\nQuery: \\\"{query}\\\"\")\n",
        "    print(\"Top matches:\")\n",
        "    for i, r in enumerate(results):\n",
        "        print(f\"  {i+1}. Slide {r['slide_number']} (similarity: {r['similarity']:.4f})\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Experiment Results\n",
        "\n",
        "### What to Look For:\n",
        "\n",
        "1. **Precision**: Does \"title slide\" query return actual title slides?\n",
        "2. **Recall**: Are all title slides ranked high?\n",
        "3. **False Positives**: Do section dividers/closing slides rank too high?\n",
        "4. **Performance**: How long did embedding generation take?\n",
        "\n",
        "### Expected Issues:\n",
        "\n",
        "- Visual similarity might cause confusion (title slides look like section dividers)\n",
        "- Need explicit categories for reliable filtering\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "If results are promising ‚Üí Implement Vector Search 2.0 with category labels\n",
        "If results are poor ‚Üí Stick with explicit categorization approach"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
